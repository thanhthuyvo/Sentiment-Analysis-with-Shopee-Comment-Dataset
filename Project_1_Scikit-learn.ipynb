{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "pB9QFDTQLgKR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'Data'\n",
      "C:\\Users\\khaih\\Downloads\\LDS0\\Data\n"
     ]
    }
   ],
   "source": [
    "%cd \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Q9i8FYWgLgKT",
    "outputId": "043c7bc9-278d-407a-da7c-857fed55b6a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "YuJxMSPTLgKU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "import regex\n",
    "import demoji\n",
    "from pyvi import ViPosTagger, ViTokenizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "jcgSHMolLgKV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "LpOsAx-XLgKV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"pre_data.csv\", delimiter=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "c7tu5kXCLgKV",
    "outputId": "8508ed00-20ac-42c7-d72d-ec41807174b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>pre_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259181</th>\n",
       "      <td>Like</td>\n",
       "      <td>vừa_vặn nâu dày đỏ trắng đỏ cổ náu đẹp nhức lá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259182</th>\n",
       "      <td>Like</td>\n",
       "      <td>hợp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259183</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp đẹp nhanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259184</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp nhanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259188</th>\n",
       "      <td>Like</td>\n",
       "      <td>gọn_gàng đẹp họa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259190</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp rẻ ổn nhanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259191</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp lắm chất_lượng aaaaaaaaaaaaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259192</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp lắm đẹp fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259193</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp hì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259194</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp chất_lượng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                        pre_comment\n",
       "259181  Like  vừa_vặn nâu dày đỏ trắng đỏ cổ náu đẹp nhức lá...\n",
       "259182  Like                                                hợp\n",
       "259183  Like                                      đẹp đẹp nhanh\n",
       "259184  Like                                          đẹp nhanh\n",
       "259188  Like                                   gọn_gàng đẹp họa\n",
       "259190  Like                                    đẹp rẻ ổn nhanh\n",
       "259191  Like                đẹp lắm chất_lượng aaaaaaaaaaaaaaaa\n",
       "259192  Like                                    đẹp lắm đẹp fit\n",
       "259193  Like                                             đẹp hì\n",
       "259194  Like                                     đẹp chất_lượng"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Ty9Yqj7TLgKW",
    "outputId": "d3615ad5-4125-4a8e-8423-2aa3f1db07f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class          0\n",
       "pre_comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "vEz_iYjuLgKW",
    "outputId": "14cae898-34ac-4bc3-ba29-f0f4b6d67454"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class          489906\n",
       "pre_comment    489906\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "uEVFxaflLgKY"
   },
   "outputs": [],
   "source": [
    "def my_tokenizer(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "dwdtz6xGLgKX"
   },
   "outputs": [],
   "source": [
    "text_data=data[\"pre_comment\"]\n",
    "target=data[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.replace(\"Like\", 0)\n",
    "target = target.replace(\"Not_Like\", 1)\n",
    "target = target.replace(\"Neutral\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<489906x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 956461 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(max_features=1000)\n",
    "count.fit(text_data)\n",
    "bag_of_words = count.transform(text_data)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bag_of_words.toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(target)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Neutral', 'Neutral',\n",
       "       'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral',\n",
       "       'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral',\n",
       "       'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral',\n",
       "       'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Neutral', 'Not_Like',\n",
       "       'Not_Like', 'Not_Like', 'Not_Like', 'Not_Like', 'Not_Like',\n",
       "       'Not_Like', 'Not_Like', 'Not_Like', 'Not_Like', 'Not_Like',\n",
       "       'Not_Like', 'Not_Like', 'Not_Like', 'Not_Like', 'Not_Like',\n",
       "       'Not_Like', 'Not_Like', 'Not_Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like', 'Like',\n",
       "       'Like', 'Like', 'Like'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"class\"].head(200).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng LazyClassifier để tìm ra các model tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "-57P7xTgLgKX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 29/29 [5:41:10<00:00, 705.88s/it]\n"
     ]
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>None</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3759.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.65</td>\n",
       "      <td>None</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3298.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>None</td>\n",
       "      <td>0.88</td>\n",
       "      <td>565.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.64</td>\n",
       "      <td>None</td>\n",
       "      <td>0.88</td>\n",
       "      <td>22.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>None</td>\n",
       "      <td>0.88</td>\n",
       "      <td>61.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.61</td>\n",
       "      <td>None</td>\n",
       "      <td>0.89</td>\n",
       "      <td>91.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2325.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.58</td>\n",
       "      <td>None</td>\n",
       "      <td>0.87</td>\n",
       "      <td>553.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.57</td>\n",
       "      <td>None</td>\n",
       "      <td>0.87</td>\n",
       "      <td>495.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.46</td>\n",
       "      <td>None</td>\n",
       "      <td>0.35</td>\n",
       "      <td>26.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.44</td>\n",
       "      <td>None</td>\n",
       "      <td>0.84</td>\n",
       "      <td>8990.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.33</td>\n",
       "      <td>None</td>\n",
       "      <td>0.78</td>\n",
       "      <td>18.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
       "Model                                                                   \n",
       "ExtraTreesClassifier        0.90               0.65    None      0.89   \n",
       "BaggingClassifier           0.89               0.65    None      0.89   \n",
       "DecisionTreeClassifier      0.89               0.64    None      0.88   \n",
       "BernoulliNB                 0.88               0.64    None      0.88   \n",
       "ExtraTreeClassifier         0.89               0.64    None      0.88   \n",
       "LogisticRegression          0.90               0.61    None      0.89   \n",
       "LinearSVC                   0.89               0.60    None      0.88   \n",
       "KNeighborsClassifier        0.89               0.58    None      0.87   \n",
       "AdaBoostClassifier          0.89               0.57    None      0.87   \n",
       "GaussianNB                  0.29               0.46    None      0.35   \n",
       "CalibratedClassifierCV      0.88               0.44    None      0.84   \n",
       "DummyClassifier             0.85               0.33    None      0.78   \n",
       "\n",
       "                        Time Taken  \n",
       "Model                               \n",
       "ExtraTreesClassifier       3759.20  \n",
       "BaggingClassifier          3298.54  \n",
       "DecisionTreeClassifier      565.39  \n",
       "BernoulliNB                  22.17  \n",
       "ExtraTreeClassifier          61.32  \n",
       "LogisticRegression           91.73  \n",
       "LinearSVC                  2325.71  \n",
       "KNeighborsClassifier        553.73  \n",
       "AdaBoostClassifier          495.63  \n",
       "GaussianNB                   26.46  \n",
       "CalibratedClassifierCV     8990.99  \n",
       "DummyClassifier              18.65  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dựa vào bảng kết quả chọn các model ExtraTreeClassifier, BernoulliNB, LogisticRegression, DecisionTreeClassifier để chạy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7CR_gWBLgKY"
   },
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1i3uDPghLgKi",
    "outputId": "269d3ca9-d574-4244-eb12-003555993e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9057377885734115\n",
      "------------------------------------------------------------\n",
      "[[82180  1211  1179]\n",
      " [ 2470  4700   395]\n",
      " [ 3105   876  1866]]\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     84570\n",
      "           1       0.69      0.62      0.65      7565\n",
      "           2       0.54      0.32      0.40      5847\n",
      "\n",
      "    accuracy                           0.91     97982\n",
      "   macro avg       0.72      0.64      0.67     97982\n",
      "weighted avg       0.89      0.91      0.90     97982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_bnl = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', BernoulliNB())\n",
    "])\n",
    "\n",
    "pipeline_bnl.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bnl = pipeline_bnl.predict(X_test)\n",
    "\n",
    "accuracy_bnl = accuracy_score(y_test, y_pred_bnl)\n",
    "print(\"Accuracy: \", accuracy_bnl)\n",
    "print(\"-\"*60)\n",
    "print(confusion_matrix(y_test, y_pred_bnl))\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred_bnl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2pqyhgBLgKj"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "uhSm4gSrLgKk",
    "outputId": "7982b5fa-bed3-4579-e024-3c5d439c7a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9124737196627952\n",
      "------------------------------------------------------------\n",
      "[[83537   801   232]\n",
      " [ 3061  4434    70]\n",
      " [ 3709   703  1435]]\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     84570\n",
      "           1       0.75      0.59      0.66      7565\n",
      "           2       0.83      0.25      0.38      5847\n",
      "\n",
      "    accuracy                           0.91     97982\n",
      "   macro avg       0.83      0.61      0.66     97982\n",
      "weighted avg       0.91      0.91      0.90     97982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = pipeline_lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"-\"*60)\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgQvGUiQLgKk"
   },
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "R5YEiCvYLgKk",
    "outputId": "21d5523f-d34d-4082-bd7a-b3534f1b72db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9057990243105877\n",
      "------------------------------------------------------------\n",
      "[[82604  1249   717]\n",
      " [ 2818  4492   255]\n",
      " [ 3411   780  1656]]\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     84570\n",
      "           1       0.69      0.59      0.64      7565\n",
      "           2       0.63      0.28      0.39      5847\n",
      "\n",
      "    accuracy                           0.91     97982\n",
      "   macro avg       0.75      0.62      0.66     97982\n",
      "weighted avg       0.89      0.91      0.89     97982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_dct = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_dct.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dct = pipeline_dct.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_dct)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"-\"*60)\n",
    "print(confusion_matrix(y_test, y_pred_dct))\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred_dct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0Q61PqeLgKl"
   },
   "source": [
    "### ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Pvetgpc7LgKl",
    "outputId": "f9b42c2b-0aa6-4121-8ffb-6d59b51361d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.903625155640832\n",
      "------------------------------------------------------------\n",
      "[[82416  1330   824]\n",
      " [ 2839  4450   276]\n",
      " [ 3377   797  1673]]\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     84570\n",
      "           1       0.68      0.59      0.63      7565\n",
      "           2       0.60      0.29      0.39      5847\n",
      "\n",
      "    accuracy                           0.90     97982\n",
      "   macro avg       0.74      0.62      0.66     97982\n",
      "weighted avg       0.89      0.90      0.89     97982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_etc = Pipeline([\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', ExtraTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_etc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_etc = pipeline_etc.predict(X_test)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_etc)\n",
    "print(\"Accuracy: \", accuracy_knn)\n",
    "print(\"-\"*60)\n",
    "print(confusion_matrix(y_test, y_pred_etc))\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred_etc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yStejAeCLgKm"
   },
   "source": [
    "### Nhận xét:\n",
    "- Sau khi chạy model cho ra accuracy khá ổn từ 80-91%, nhưng khi xem xét lại recall và f1-score, nhận thấy rằng các model chưa thực sự hiệu quả và cần cải thiện\n",
    "\n",
    "- Có thể Resample Data để cân bằng lại dữ liệu và xem tính hiệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBVqaHWQLgKm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
