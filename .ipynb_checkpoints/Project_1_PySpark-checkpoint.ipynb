{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63Bhl4Ey2euX"
   },
   "outputs": [],
   "source": [
    "# !pip install underthesea\n",
    "# !pip install demoji\n",
    "# !pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH8XoOcXwJna"
   },
   "outputs": [],
   "source": [
    "# !apt update\n",
    "# !apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "# !wget -q http://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
    "# !tar -xvf spark-3.3.0-bin-hadoop3.tgz\n",
    "# !pip install -q findspark\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGy1fE8h2g2m"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "\n",
    "# %cd '/content/gdrive/My Drive/Data_Sicience/LDS0_K282_ONLINE_LuuNguyenKhaiHoan/Project_1/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter contrib nbextension install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ovT6M6nPKQje",
    "outputId": "c34ff7e9-d094-4b92-b26e-bf342f791ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khaih\\Downloads\\LDS0\\Data\n"
     ]
    }
   ],
   "source": [
    "%cd \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "NoveTrE9tGAA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "import demoji\n",
    "from pyvi import ViPosTagger, ViTokenizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "pK_5r2Fhwzl3"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/My Drive/Data_Sicience/LDS0_K282_ONLINE_LuuNguyenKhaiHoan/Project_1/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "UQnB7R5YuMX8"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "HHd9qN41KQjf"
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "bSRwsQ6ouP8y"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import LogisticRegression, LinearSVC\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.sql.functions import col, lit\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "import regex\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9iOF-T3CuSdK"
   },
   "outputs": [],
   "source": [
    "#SparkContext.setSystemProperty('spark.executor.memory', '12g')\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.memory', '12g')\n",
    "conf.set('spark.driver.memory', '20g')\n",
    "conf.set('spark.cores.max', '16')\n",
    "conf.set('spark.network.timeout', '60')\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cudQp_DFuTzS"
   },
   "outputs": [],
   "source": [
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TcL_60EDKQjg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"pre_data.csv\", delimiter=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1675689563037,
     "user": {
      "displayName": "Lưu Nguyễn Khải Hoàn",
      "userId": "12754983180713265756"
     },
     "user_tz": -420
    },
    "id": "N8yEiKr7uiSW",
    "outputId": "dd9a3c80-ab55-4845-b46d-fd8f1da22387"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>pre_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259179</th>\n",
       "      <td>Like</td>\n",
       "      <td>kiểm không</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259180</th>\n",
       "      <td>Like</td>\n",
       "      <td>cho_phép sơ_suất hát hoạt_động rõ_ràng saisĩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259181</th>\n",
       "      <td>Like</td>\n",
       "      <td>vừa_vặn không nâu dày đỏ trắng đỏ cổ náu đẹp n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259182</th>\n",
       "      <td>Like</td>\n",
       "      <td>đầu_shop hợp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259183</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp đẹp hàng thích</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                        pre_comment\n",
       "259179  Like                                         kiểm không\n",
       "259180  Like       cho_phép sơ_suất hát hoạt_động rõ_ràng saisĩ\n",
       "259181  Like  vừa_vặn không nâu dày đỏ trắng đỏ cổ náu đẹp n...\n",
       "259182  Like                                       đầu_shop hợp\n",
       "259183  Like                                 đẹp đẹp hàng thích"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k3iZrGK9KQjh",
    "outputId": "50846a06-ca97-4487-f8c0-aee9f364b323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 509691 entries, 259179 to 1319048\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   class        509691 non-null  object\n",
      " 1   pre_comment  509691 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"pre_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MsKAYx3n-_Am"
   },
   "outputs": [],
   "source": [
    "stringcols = data.select_dtypes(include='object').columns\n",
    "data[stringcols] = data[stringcols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1675691456722,
     "user": {
      "displayName": "Lưu Nguyễn Khải Hoàn",
      "userId": "12754983180713265756"
     },
     "user_tz": -420
    },
    "id": "Qh8vUKQj9S_F",
    "outputId": "fc86c21a-bab9-4602-e8e2-aadaefcefb2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>pre_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259179</th>\n",
       "      <td>Like</td>\n",
       "      <td>kiểm không</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259180</th>\n",
       "      <td>Like</td>\n",
       "      <td>cho_phép sơ_suất hát hoạt_động rõ_ràng saisĩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259181</th>\n",
       "      <td>Like</td>\n",
       "      <td>vừa_vặn không nâu dày đỏ trắng đỏ cổ náu đẹp n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259182</th>\n",
       "      <td>Like</td>\n",
       "      <td>đầu_shop hợp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259183</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp đẹp hàng thích</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319014</th>\n",
       "      <td>Like</td>\n",
       "      <td>đóng_gói đẹp tốt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319017</th>\n",
       "      <td>Like</td>\n",
       "      <td>tốt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319036</th>\n",
       "      <td>Like</td>\n",
       "      <td>tuyệt_vời</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319045</th>\n",
       "      <td>Like</td>\n",
       "      <td>tốt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319048</th>\n",
       "      <td>Not_Like</td>\n",
       "      <td>kém</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509691 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class                                        pre_comment\n",
       "259179       Like                                         kiểm không\n",
       "259180       Like       cho_phép sơ_suất hát hoạt_động rõ_ràng saisĩ\n",
       "259181       Like  vừa_vặn không nâu dày đỏ trắng đỏ cổ náu đẹp n...\n",
       "259182       Like                                       đầu_shop hợp\n",
       "259183       Like                                 đẹp đẹp hàng thích\n",
       "...           ...                                                ...\n",
       "1319014      Like                                   đóng_gói đẹp tốt\n",
       "1319017      Like                                                tốt\n",
       "1319036      Like                                          tuyệt_vời\n",
       "1319045      Like                                                tốt\n",
       "1319048  Not_Like                                                kém\n",
       "\n",
       "[509691 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[stringcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NYtKej6YANZJ",
    "outputId": "d7787628-403c-4eae-be16-2dc619c10836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- pre_comment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_data=spark.createDataFrame(data) \n",
    "sub_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yB8zPXqaKQji",
    "outputId": "0ed6a5fa-0064-43a9-bedb-4bf3efd966af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|         pre_comment|\n",
      "+-----+--------------------+\n",
      "| Like|          kiểm không|\n",
      "| Like|cho_phép sơ_suất ...|\n",
      "| Like|vừa_vặn không nâu...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5j14b0GKKQji"
   },
   "outputs": [],
   "source": [
    "df_pre=sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fdaE1JdUKQji"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='pre_comment', outputCol='token_text')\n",
    "# stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='token_text', outputCol='c_vec')\n",
    "idf = IDF(inputCol='c_vec', outputCol='tf_idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
    "#Fits a model to the input dataset with optional parameters.\n",
    "df_pre = class_to_num.fit(df_pre).transform(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "m-vFYdk9KQji"
   },
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols=['tf_idf'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "niUu5trmKQji",
    "outputId": "97e04c0c-0669-4e85-cc83-69ec8877729f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509691"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "h_R1MiQQKQjj"
   },
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages= [\n",
    "                            tokenizer,\n",
    "                            count_vec,\n",
    "                            idf,\n",
    "                            clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "uHlUhuNMKQjj"
   },
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipe.fit(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.save(\"C:\\Users\\khaih\\Downloads\\Test_model\\Data/Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "dmpXfRuZKQjj"
   },
   "outputs": [],
   "source": [
    "clean_data= cleaner.transform(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "GP2E72evKQjj"
   },
   "outputs": [],
   "source": [
    "clean_data=clean_data.select(['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "QZBmp734KQjj"
   },
   "outputs": [],
   "source": [
    "(training, testing) = clean_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "zDMz41k_KQjj",
    "outputId": "509c185b-b796-4ce7-b161-66c991d70d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  0.0|347729|\n",
      "|  1.0| 34229|\n",
      "|  2.0| 26246|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "FDxwmleWKQjj",
    "outputId": "6e2cb882-1a11-4103-d966-418aca676db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "WZHs5aYhKQjk",
    "outputId": "b3b4d666-24ca-4b44-95e2-e82f3091cbe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio like/neutral: 10\n",
      "ratio like/not_like: 13\n"
     ]
    }
   ],
   "source": [
    "like_df = training.filter(col(\"label\") == 0)\n",
    "neutral_df = training.filter(col(\"label\") == 1)\n",
    "not_like_df = training.filter(col(\"label\") == 2)\n",
    "ratio_1 = int(like_df.count()/neutral_df.count())\n",
    "ratio_2 = int(like_df.count()/not_like_df.count())\n",
    "print(\"ratio like/neutral: {}\".format(ratio_1))\n",
    "print(\"ratio like/not_like: {}\".format(ratio_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "na5ycrY6KQjk",
    "outputId": "1f7bf9ca-7351-4327-8692-f06cb10e462c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# resample neutral\n",
    "neutral_resample = range(ratio_1)\n",
    "\n",
    "oversampled_neutral_df = neutral_df.withColumn(\"dummy\", explode(array([lit(x) for x in neutral_resample]))).drop('dummy')\n",
    "\n",
    "final_training_df = like_df.unionAll(oversampled_neutral_df)\n",
    "final_training_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "nlrbZpOKKQjk",
    "outputId": "52e6a632-3bd0-4f5f-f1aa-aea88edc8abd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  0.0|347729|\n",
      "|  1.0|342290|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_training_df.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "_EsOP14oKQjk",
    "outputId": "9a055ac5-6a6f-4961-acdd-70f6dbfc3815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "|  0.0|(53679,[0],[0.931...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# resample not_like\n",
    "not_like_resample = range(ratio_2)\n",
    "\n",
    "oversampled_notlike_df = not_like_df.withColumn(\"dummy\",explode(array([lit(x) for x in not_like_resample]))).drop('dummy')\n",
    "\n",
    "final_training_df = final_training_df.unionAll(oversampled_notlike_df)\n",
    "final_training_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (final_training_df, final_testing_df) = final_training_df.randomSplit([0.8,0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "PL5fqygCKQjk",
    "outputId": "2bc13bd1-1956-4e14-a9a5-799661949d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  0.0|347729|\n",
      "|  1.0|342290|\n",
      "|  2.0|341198|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_training_df.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNssIjGoKQjl"
   },
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "4UX8nmJ8KQjn"
   },
   "outputs": [],
   "source": [
    "decisionTree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "OM_dU_HoKQjn"
   },
   "outputs": [],
   "source": [
    "predictor_decisionTree = decisionTree.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2MB8M0wNKQjn"
   },
   "outputs": [],
   "source": [
    "test_results_decisionTree = predictor_decisionTree.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Mzix9dLdKQjo",
    "outputId": "0c661343-ccb1-4e89-b1dd-6a9ab0d31452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 8505|\n",
      "|  2.0|       2.0| 6539|\n",
      "|  0.0|       0.0|87100|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results_decisionTree.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_decisionTree_rdd=test_results_decisionTree.select(\"label\",\"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\spark-3.3.1-bin-hadoop3\\python\\pyspark\\sql\\context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 precision = 1.0\n",
      "Class 0.0 recall = 1.0\n",
      "Class 0.0 F1 Measure = 1.0\n",
      "Class 1.0 precision = 1.0\n",
      "Class 1.0 recall = 1.0\n",
      "Class 1.0 F1 Measure = 1.0\n",
      "Class 2.0 precision = 1.0\n",
      "Class 2.0 recall = 1.0\n",
      "Class 2.0 F1 Measure = 1.0\n"
     ]
    }
   ],
   "source": [
    "#predictionAndLabels = test_results_NaiveBayes.select(\"label\",\"prediction\")\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "#predictionAndLabels = test_results_lg.select(\"label\",\"prediction\").rdd\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics_decisionTree = MulticlassMetrics(test_results_decisionTree_rdd)\n",
    "\n",
    "# Statistics by class\n",
    "labels = test_results_decisionTree_rdd.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics_decisionTree.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics_decisionTree.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics_decisionTree.fMeasure(label, beta=1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "LpdHmP2uKQjo",
    "outputId": "7af23189-9c0a-45c0-d6c4-dc34209e9c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model at  presicting like - dislike - neutral is: 1.0\n"
     ]
    }
   ],
   "source": [
    "acc_eval_decisionTree = MulticlassClassificationEvaluator()\n",
    "acc_decisionTree = acc_eval_decisionTree.evaluate(test_results_decisionTree)\n",
    "print(\"Accuracy of Model at  presicting like - dislike - neutral is: {}\".format(acc_decisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_decisionTree.save(\"Project_1_DecisionTree_pyspark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP_qeSfTKQjo"
   },
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Ro65C2HVKQjp"
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WtvfygT9KQjp"
   },
   "outputs": [],
   "source": [
    "predictor_NaiveBayes = nb.fit(final_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "EQ1MZXZOKQjp"
   },
   "outputs": [],
   "source": [
    "test_results_NaiveBayes = predictor_NaiveBayes.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "mER7TIfiKQjp",
    "outputId": "f761f23a-eb61-4629-a39a-90205d2ea153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  2.0|       0.0|  198|\n",
      "|  1.0|       1.0| 5598|\n",
      "|  0.0|       1.0| 3842|\n",
      "|  1.0|       0.0|  237|\n",
      "|  2.0|       2.0| 5102|\n",
      "|  2.0|       1.0| 1239|\n",
      "|  1.0|       2.0| 2670|\n",
      "|  0.0|       0.0|75023|\n",
      "|  0.0|       2.0| 8235|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results_NaiveBayes.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "N4DUlyoYKQjp",
    "outputId": "9293088e-678e-46a9-9008-f25988e9a55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model at presicting  like - dislike - neutral is: 0.864652196931057\n"
     ]
    }
   ],
   "source": [
    "acc_eval_NaiveBayes = MulticlassClassificationEvaluator()\n",
    "acc_NaiveBayes = acc_eval_NaiveBayes.evaluate(test_results_NaiveBayes)\n",
    "print(\"Accuracy of Model at presicting  like - dislike - neutral is: {}\".format(acc_NaiveBayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_NaiveBayes_rdd=test_results_NaiveBayes.select(\"label\",\"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 precision = 0.8613432835820896\n",
      "Class 0.0 recall = 0.9942352036894696\n",
      "Class 0.0 F1 Measure = 0.9230305490963225\n",
      "Class 1.0 precision = 0.6582010582010582\n",
      "Class 1.0 recall = 0.5242063863657646\n",
      "Class 1.0 F1 Measure = 0.5836113427856546\n",
      "Class 2.0 precision = 0.7802416271601162\n",
      "Class 2.0 recall = 0.318735553195477\n",
      "Class 2.0 F1 Measure = 0.45258582453650315\n"
     ]
    }
   ],
   "source": [
    "#predictionAndLabels = test_results_NaiveBayes.select(\"label\",\"prediction\")\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "#predictionAndLabels = test_results_lg.select(\"label\",\"prediction\").rdd\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(test_results_NaiveBayes_rdd)\n",
    "\n",
    "# Statistics by class\n",
    "labels = test_results_NaiveBayes_rdd.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_NaiveBayes.save(\"Project_1_NaiveBayes_pyspark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9fT2nHRKQjp"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "KY4-kmWrKQjp"
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(featuresCol='features',labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "M-WfVZPcKQjq"
   },
   "outputs": [],
   "source": [
    "predictor_lg = lg.fit(final_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "cgz4usxNKQjq"
   },
   "outputs": [],
   "source": [
    "test_results_lg = predictor_lg.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "zEO6SB7dKQjq",
    "outputId": "5970afdb-516d-4c7a-9b28-6e448a0b3288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  2.0|       0.0|  987|\n",
      "|  1.0|       1.0| 6171|\n",
      "|  0.0|       1.0| 3389|\n",
      "|  1.0|       0.0|  592|\n",
      "|  2.0|       2.0| 3973|\n",
      "|  2.0|       1.0| 1479|\n",
      "|  1.0|       2.0| 1704|\n",
      "|  0.0|       0.0|73023|\n",
      "|  0.0|       2.0|10169|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results_lg.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_lg_rdd=test_results_lg.select(\"label\",\"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\spark-3.3.1-bin-hadoop3\\python\\pyspark\\sql\\context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 precision = 0.8434067520587658\n",
      "Class 0.0 recall = 0.9788343476046218\n",
      "Class 0.0 F1 Measure = 0.9060881110290787\n",
      "Class 1.0 precision = 0.7288295736388332\n",
      "Class 1.0 recall = 0.5590180269951989\n",
      "Class 1.0 F1 Measure = 0.6327283912642264\n",
      "Class 2.0 precision = 0.6170212765957447\n",
      "Class 2.0 recall = 0.25072573520131264\n",
      "Class 2.0 F1 Measure = 0.3565627103432802\n"
     ]
    }
   ],
   "source": [
    "#predictionAndLabels = test_results_NaiveBayes.select(\"label\",\"prediction\")\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "#predictionAndLabels = test_results_lg.select(\"label\",\"prediction\").rdd\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(test_results_lg_rdd)\n",
    "\n",
    "# Statistics by class\n",
    "labels = test_results_lg_rdd.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "JtRAveVxKQjq",
    "outputId": "16165815-2ca1-4c35-bf13-b181e64168c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting  like - dislike - neutral is: 0.8484163816227029\n"
     ]
    }
   ],
   "source": [
    "acc_eval_lg = MulticlassClassificationEvaluator()\n",
    "acc_lg = acc_eval_lg.evaluate(test_results_lg)\n",
    "print(\"Accuracy of model at predicting  like - dislike - neutral is: {}\".format(acc_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lg.save('Project_1_LogisticRegression_pyspark_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOAD EMOJICON\n",
    "file = open('files/emojicon.txt', 'r', encoding=\"utf8\")\n",
    "emoji_lst = file.read().split('\\n')\n",
    "emoji_dict = {}\n",
    "for line in emoji_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    emoji_dict[key] = str(value)\n",
    "file.close()\n",
    "#################\n",
    "#LOAD TEENCODE\n",
    "file = open('files/teencode.txt', 'r', encoding=\"utf8\")\n",
    "teen_lst = file.read().split('\\n')\n",
    "teen_dict = {}\n",
    "for line in teen_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    teen_dict[key] = str(value)\n",
    "file.close()\n",
    "###############\n",
    "#LOAD TRANSLATE ENGLISH -> VNMESE\n",
    "file = open('files/english-vnmese.txt', 'r', encoding=\"utf8\")\n",
    "english_lst = file.read().split('\\n')\n",
    "english_dict = {}\n",
    "for line in english_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    english_dict[key] = str(value)\n",
    "file.close()\n",
    "################\n",
    "#LOAD wrong words\n",
    "file = open('files/wrong-word.txt', 'r', encoding=\"utf8\")\n",
    "wrong_lst = file.read().split('\\n')\n",
    "file.close()\n",
    "#################\n",
    "#LOAD STOPWORDS\n",
    "file = open('files/vietnamese-stopwords.txt', 'r', encoding=\"utf8\")\n",
    "stopwords_lst = file.read().split('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, emoji_dict, teen_dict, wrong_lst):\n",
    "    document = text.lower()\n",
    "    document = document.replace(\"’\",'')\n",
    "    document = regex.sub(r'\\.+', \".\", document)\n",
    "    new_sentence =''\n",
    "    for sentence in sent_tokenize(document):\n",
    "        # if not(sentence.isascii()):\n",
    "        ###### CONVERT EMOJICON\n",
    "        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))\n",
    "        ###### CONVERT TEENCODE\n",
    "        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())\n",
    "        ###### DEL Punctuation & Numbers\n",
    "        pattern = r'(?i)\\b[a-záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ]+\\b'\n",
    "        sentence = ' '.join(regex.findall(pattern,sentence))\n",
    "        ###### DEL wrong words   \n",
    "        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())\n",
    "        new_sentence = new_sentence+ sentence + '. '                    \n",
    "    document = new_sentence  \n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa unicode tiếng việt\n",
    "def loaddicchar():\n",
    "    uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "    unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    " \n",
    "# Đưa toàn bộ dữ liệu qua hàm này để chuẩn hóa lại\n",
    "def convert_unicode(txt):\n",
    "    dicchar = loaddicchar()\n",
    "    return regex.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# có thể bổ sung thêm các từ: chẳng, chả...\n",
    "def process_special_word(text):\n",
    "    new_text = ''\n",
    "    text_lst = text.split()\n",
    "    i= 0\n",
    "    if 'không' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "#             print(word)\n",
    "#             print(i)\n",
    "            if  word == 'không':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "#                     print(word)\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "    if 'tạm' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "#             print(word)\n",
    "#             print(i)\n",
    "            if  word == 'tạm':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "#                     print(word)\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "    if 'hơi' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "#             print(word)\n",
    "#             print(i)\n",
    "            if  word == 'hơi':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "#                     print(word)\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "            #print(new_text)\n",
    "    else:\n",
    "        new_text = text\n",
    "    return new_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_postag_thesea(text):\n",
    "    new_document = ''\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('.','')\n",
    "        ###### POS tag\n",
    "        lst_word_type = ['A','AB','V','VB','VY','R','M']\n",
    "        #lst_word_type = ['A','AB','V','VB','VY','R']\n",
    "        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format=\"text\"))))\n",
    "        new_document = new_document + sentence + ' '\n",
    "    ###### DEL excess blank space\n",
    "    new_document = regex.sub(r'\\s+', ' ', new_document).strip()\n",
    "    return new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text, stopwords):\n",
    "    ###### REMOVE stop words\n",
    "    document = ' '.join('' if word in stopwords else word for word in text.split())\n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "model_1 = LogisticRegressionModel.load('Project_1_LogisticRegression_pyspark_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_1=\"Đúng y như hình, nhưng lúc giao bị rớt cục nhỏ ra, ko chắc chắn, lúc lăn kêu két két nhưng dùng vẫn ok\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xu_li_text(text):\n",
    "    document=  process_text(text,emoji_dict,teen_dict,wrong_lst)\n",
    "    document = convert_unicode(document)\n",
    "    document = process_postag_thesea(document)\n",
    "    document = remove_stopword(document, stopwords_lst)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|pre_comment         |\n",
      "+--------------------+\n",
      "|rớt không lăn kêu ổn|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StringType\n",
    "sentences = spark.createDataFrame([\n",
    "    Row(pre_comment=xu_li_text(str_1))])\n",
    "sentences.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rớt không lăn kêu ổn'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.select(\"pre_comment\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = cleaner.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         pre_comment|          token_text|               c_vec|              tf_idf|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|rớt không lăn kêu ổn|[rớt, không, lăn,...|(53679,[1,5,208,5...|(53679,[1,5,208,5...|(53679,[1,5,208,5...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_text.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|         pre_comment|prediction|\n",
      "+--------------------+----------+\n",
      "|rớt không lăn kêu ổn|       1.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prec_1=model_1.transform(test_text)\n",
    "prec_1=prec_1.select(\"pre_comment\",\"prediction\")\n",
    "prec_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_1.select(\"prediction\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like\n"
     ]
    }
   ],
   "source": [
    "if prec_1.select(\"prediction\").collect()[0][0]==1.0:\n",
    "    print(\"Like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0:like\n",
    "2: dislike\n",
    "1: neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "pipeline_test=PipelineModel.load('Project_1_Pipeline_pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pipeline_test.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         pre_comment|          token_text|               c_vec|              tf_idf|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|rớt không lăn kêu ổn|[rớt, không, lăn,...|(53679,[1,5,208,5...|(53679,[1,5,208,5...|(53679,[1,5,208,5...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_text.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JDd8n73KQjq"
   },
   "source": [
    "### Nhận xét:\n",
    "- Các model chạy bằng thư viện pyspark đều cho ra kết quả khá tốt (83 - 99%).\n",
    "- Xem xét recall, f1 Measure, precision ta thấy model NaiveBayes chưa thực sự tốt. Ngược lại model LogisticRegression cho ra accuracy lẫn recall, f1 Measure, precision đều khá cao.\n",
    "\n",
    "=> Model LogisticRegression cho ra kết quả tốt nhất và có thể áp dụng model này.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Do cấu hình máy yếu nên em không thể chạy model RandomForestClassifier và một số model còn lại.\n",
    "- Các model GBT, SVC chỉ hỗ trợ chạy được 2 classes không thể chạy 3 classes trở lên"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JXCJ4axKQjq"
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Lwtq1U1qKQjr"
   },
   "outputs": [],
   "source": [
    "# rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4EWX9TAKQjr"
   },
   "outputs": [],
   "source": [
    "# predictor_rfc = rfc.fit(final_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GB6lmzJrKQjr"
   },
   "outputs": [],
   "source": [
    "# test_results_rfc = predictor_rfc.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qxneC-4KQjr"
   },
   "outputs": [],
   "source": [
    "# test_results_rfc.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-zyyeRAKQjr"
   },
   "outputs": [],
   "source": [
    "# acc_eval_rfc = MulticlassClassificationEvaluator()\n",
    "# acc_rfc = acc_eval_rfc.evaluate(test_results_rfc)\n",
    "# print(\"Accuracy of Model at  presicting like - dislike - neutral is: {}\".format(acc_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqr5bD9XKQjr"
   },
   "source": [
    "### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAu3k2BSKQjr"
   },
   "outputs": [],
   "source": [
    "# gbt= GBTClassifier(maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNNctUNgKQjs"
   },
   "outputs": [],
   "source": [
    "# predictor_gbt = gbt.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKE150TZKQjs"
   },
   "outputs": [],
   "source": [
    "# test_results_gbt = predictor_gbt.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuFfcSPEKQjs"
   },
   "outputs": [],
   "source": [
    "# test_results_gbt.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFoPbZbsKQjs"
   },
   "outputs": [],
   "source": [
    "# acc_eval_gbt = MulticlassClassificationEvaluator()\n",
    "# acc_gbt = acc_eval_gbt.evaluate(test_results_gbt)\n",
    "# print(\"Accuracy of Model at  presicting spam ham is: {}\".format(acc_gbt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOCaBI9WKQjs"
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KnXOha-1KQjs"
   },
   "outputs": [],
   "source": [
    "# lsvc = LinearSVC(maxIter=10, regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4R2iJHptKQjs"
   },
   "outputs": [],
   "source": [
    "# predictor_lsvc = lsvc.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABgizR92KQjs"
   },
   "outputs": [],
   "source": [
    "# test_results_lsvc = predictor_lsvc.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD7P2XKcKQjt"
   },
   "outputs": [],
   "source": [
    "# test_results_lsvc.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsvrFHNrKQjt"
   },
   "outputs": [],
   "source": [
    "# acc_eval_lsvc = MulticlassClassificationEvaluator()\n",
    "# acc_lsvc = acc_eval_lsvc.evaluate(test_results_lg)\n",
    "# print(\"Accuracy of model at predicting  like - dislike - neutral is: {}\".format(acc_lsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnIpFa4eKQjt"
   },
   "source": [
    "### One and Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzEBc6nlKQjt"
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import OneVsRest\n",
    "# ovr = OneVsRest(classifier=GBTClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FG1yDNfeKQjt"
   },
   "outputs": [],
   "source": [
    "# predictor_ovr = ovr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtnvPq8uKQjt"
   },
   "outputs": [],
   "source": [
    "# test_results_ovr = predictor_ovr.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOdsMQ6BKQju"
   },
   "outputs": [],
   "source": [
    "# test_results_ovr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCh3AUK8KQju"
   },
   "outputs": [],
   "source": [
    "# test_results_ovr.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNL4nEu0KQju"
   },
   "outputs": [],
   "source": [
    "# acc_eval = MulticlassClassificationEvaluator()\n",
    "# acc_1 = acc_eval.evaluate(test_results_ovr)\n",
    "# print(\"Accuracy of model at predicting: {}\".format(acc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "N3MfYahWKQju"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
