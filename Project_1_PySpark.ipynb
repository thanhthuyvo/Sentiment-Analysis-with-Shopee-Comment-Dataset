{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63Bhl4Ey2euX"
   },
   "outputs": [],
   "source": [
    "# !pip install underthesea\n",
    "# !pip install demoji\n",
    "# !pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH8XoOcXwJna"
   },
   "outputs": [],
   "source": [
    "# !apt update\n",
    "# !apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "# !wget -q http://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
    "# !tar -xvf spark-3.3.0-bin-hadoop3.tgz\n",
    "# !pip install -q findspark\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGy1fE8h2g2m"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "\n",
    "# %cd '/content/gdrive/My Drive/Data_Sicience/LDS0_K282_ONLINE_LuuNguyenKhaiHoan/Project_1/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter contrib nbextension install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ovT6M6nPKQje",
    "outputId": "c34ff7e9-d094-4b92-b26e-bf342f791ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khaih\\Downloads\\LDS0\\Data\n"
     ]
    }
   ],
   "source": [
    "%cd \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NoveTrE9tGAA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "import demoji\n",
    "from pyvi import ViPosTagger, ViTokenizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pK_5r2Fhwzl3"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/My Drive/Data_Sicience/LDS0_K282_ONLINE_LuuNguyenKhaiHoan/Project_1/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UQnB7R5YuMX8"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HHd9qN41KQjf"
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bSRwsQ6ouP8y"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import LogisticRegression, LinearSVC\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.sql.functions import col, lit\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "import regex\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9iOF-T3CuSdK"
   },
   "outputs": [],
   "source": [
    "#SparkContext.setSystemProperty('spark.executor.memory', '12g')\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.memory', '12g')\n",
    "conf.set('spark.driver.memory', '20g')\n",
    "conf.set('spark.cores.max', '16')\n",
    "conf.set('spark.network.timeout', '60')\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cudQp_DFuTzS"
   },
   "outputs": [],
   "source": [
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TcL_60EDKQjg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"pre_data.csv\", delimiter=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1675689563037,
     "user": {
      "displayName": "Lưu Nguyễn Khải Hoàn",
      "userId": "12754983180713265756"
     },
     "user_tz": -420
    },
    "id": "N8yEiKr7uiSW",
    "outputId": "dd9a3c80-ab55-4845-b46d-fd8f1da22387"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>pre_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259179</th>\n",
       "      <td>Like</td>\n",
       "      <td>kiểm không</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259180</th>\n",
       "      <td>Like</td>\n",
       "      <td>cho_phép sơ_suất hát hoạt_động rõ_ràng saisĩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259181</th>\n",
       "      <td>Like</td>\n",
       "      <td>vừa_vặn không nâu dày đỏ trắng đỏ cổ náu đẹp n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259182</th>\n",
       "      <td>Like</td>\n",
       "      <td>đầu_shop hợp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259183</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp đẹp hàng thích</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                        pre_comment\n",
       "259179  Like                                         kiểm không\n",
       "259180  Like       cho_phép sơ_suất hát hoạt_động rõ_ràng saisĩ\n",
       "259181  Like  vừa_vặn không nâu dày đỏ trắng đỏ cổ náu đẹp n...\n",
       "259182  Like                                       đầu_shop hợp\n",
       "259183  Like                                 đẹp đẹp hàng thích"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k3iZrGK9KQjh",
    "outputId": "50846a06-ca97-4487-f8c0-aee9f364b323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 509691 entries, 259179 to 1319048\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   class        509691 non-null  object\n",
      " 1   pre_comment  509691 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"pre_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MsKAYx3n-_Am"
   },
   "outputs": [],
   "source": [
    "stringcols = data.select_dtypes(include='object').columns\n",
    "data[stringcols] = data[stringcols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1675691456722,
     "user": {
      "displayName": "Lưu Nguyễn Khải Hoàn",
      "userId": "12754983180713265756"
     },
     "user_tz": -420
    },
    "id": "Qh8vUKQj9S_F",
    "outputId": "fc86c21a-bab9-4602-e8e2-aadaefcefb2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>pre_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259179</th>\n",
       "      <td>Like</td>\n",
       "      <td>kiểm không</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259180</th>\n",
       "      <td>Like</td>\n",
       "      <td>cho_phép sơ_suất hát hoạt_động rõ_ràng saisĩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259181</th>\n",
       "      <td>Like</td>\n",
       "      <td>vừa_vặn không nâu dày đỏ trắng đỏ cổ náu đẹp n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259182</th>\n",
       "      <td>Like</td>\n",
       "      <td>đầu_shop hợp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259183</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp đẹp hàng thích</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319014</th>\n",
       "      <td>Like</td>\n",
       "      <td>đóng_gói đẹp tốt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319017</th>\n",
       "      <td>Like</td>\n",
       "      <td>tốt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319036</th>\n",
       "      <td>Like</td>\n",
       "      <td>tuyệt_vời</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319045</th>\n",
       "      <td>Like</td>\n",
       "      <td>tốt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319048</th>\n",
       "      <td>Not_Like</td>\n",
       "      <td>kém</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509691 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class                                        pre_comment\n",
       "259179       Like                                         kiểm không\n",
       "259180       Like       cho_phép sơ_suất hát hoạt_động rõ_ràng saisĩ\n",
       "259181       Like  vừa_vặn không nâu dày đỏ trắng đỏ cổ náu đẹp n...\n",
       "259182       Like                                       đầu_shop hợp\n",
       "259183       Like                                 đẹp đẹp hàng thích\n",
       "...           ...                                                ...\n",
       "1319014      Like                                   đóng_gói đẹp tốt\n",
       "1319017      Like                                                tốt\n",
       "1319036      Like                                          tuyệt_vời\n",
       "1319045      Like                                                tốt\n",
       "1319048  Not_Like                                                kém\n",
       "\n",
       "[509691 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[stringcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NYtKej6YANZJ",
    "outputId": "d7787628-403c-4eae-be16-2dc619c10836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- pre_comment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_data=spark.createDataFrame(data) \n",
    "sub_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yB8zPXqaKQji",
    "outputId": "0ed6a5fa-0064-43a9-bedb-4bf3efd966af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|         pre_comment|\n",
      "+-----+--------------------+\n",
      "| Like|          kiểm không|\n",
      "| Like|cho_phép sơ_suất ...|\n",
      "| Like|vừa_vặn không nâu...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "5j14b0GKKQji"
   },
   "outputs": [],
   "source": [
    "df_pre=sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|         pre_comment|\n",
      "+-----+--------------------+\n",
      "| Like|          kiểm không|\n",
      "| Like|cho_phép sơ_suất ...|\n",
      "| Like|vừa_vặn không nâu...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pre.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
    "# #Fits a model to the input dataset with optional parameters.\n",
    "# df_pre = class_to_num.fit(df_pre).transform(df_pre)\n",
    "# df_pre.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "fdaE1JdUKQji"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='pre_comment', outputCol='token_text')\n",
    "# stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='token_text', outputCol='c_vec')\n",
    "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
    "class_to_num = StringIndexer(inputCol='class',outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "m-vFYdk9KQji"
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['tf_idf','label'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niUu5trmKQji",
    "outputId": "97e04c0c-0669-4e85-cc83-69ec8877729f"
   },
   "outputs": [],
   "source": [
    "df_pre.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "h_R1MiQQKQjj"
   },
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages= [tokenizer,\n",
    "                            count_vec,\n",
    "                            idf,class_to_num,\n",
    "                            assembler,lg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHlUhuNMKQjj"
   },
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipe.fit(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaner.save(r\"C:\\Users\\khaih\\Downloads\\Test_model\\Data\\Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmpXfRuZKQjj"
   },
   "outputs": [],
   "source": [
    "clean_data= cleaner.transform(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP2E72evKQjj"
   },
   "outputs": [],
   "source": [
    "clean_data=clean_data.select(['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QZBmp734KQjj"
   },
   "outputs": [],
   "source": [
    "(training, testing) = df_pre.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDMz41k_KQjj",
    "outputId": "509c185b-b796-4ce7-b161-66c991d70d0c"
   },
   "outputs": [],
   "source": [
    "training.groupby(\"class\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDxwmleWKQjj",
    "outputId": "6e2cb882-1a11-4103-d966-418aca676db5"
   },
   "outputs": [],
   "source": [
    "testing.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZHs5aYhKQjk",
    "outputId": "b3b4d666-24ca-4b44-95e2-e82f3091cbe7"
   },
   "outputs": [],
   "source": [
    "like_df = training.filter(col(\"class\") == \"Like\")\n",
    "neutral_df = training.filter(col(\"class\") == \"Neutral\")\n",
    "not_like_df = training.filter(col(\"class\") == \"Not_Like\")\n",
    "ratio_1 = int(like_df.count()/neutral_df.count())\n",
    "ratio_2 = int(like_df.count()/not_like_df.count())\n",
    "print(\"ratio like/neutral: {}\".format(ratio_1))\n",
    "print(\"ratio like/not_like: {}\".format(ratio_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "na5ycrY6KQjk",
    "outputId": "1f7bf9ca-7351-4327-8692-f06cb10e462c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resample neutral\n",
    "neutral_resample = range(ratio_1)\n",
    "\n",
    "oversampled_neutral_df = neutral_df.withColumn(\"dummy\", explode(array([lit(x) for x in neutral_resample]))).drop('dummy')\n",
    "\n",
    "final_training_df = like_df.unionAll(oversampled_neutral_df)\n",
    "final_training_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlrbZpOKKQjk",
    "outputId": "52e6a632-3bd0-4f5f-f1aa-aea88edc8abd"
   },
   "outputs": [],
   "source": [
    "final_training_df.groupBy(\"class\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EsOP14oKQjk",
    "outputId": "9a055ac5-6a6f-4961-acdd-70f6dbfc3815"
   },
   "outputs": [],
   "source": [
    "# resample not_like\n",
    "not_like_resample = range(ratio_2)\n",
    "\n",
    "oversampled_notlike_df = not_like_df.withColumn(\"dummy\",explode(array([lit(x) for x in not_like_resample]))).drop('dummy')\n",
    "\n",
    "final_training_df = final_training_df.unionAll(oversampled_notlike_df)\n",
    "final_training_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (final_training_df, final_testing_df) = final_training_df.randomSplit([0.8,0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PL5fqygCKQjk",
    "outputId": "2bc13bd1-1956-4e14-a9a5-799661949d49"
   },
   "outputs": [],
   "source": [
    "final_training_df.groupBy(\"class\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNssIjGoKQjl"
   },
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UX8nmJ8KQjn"
   },
   "outputs": [],
   "source": [
    "decisionTree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OM_dU_HoKQjn"
   },
   "outputs": [],
   "source": [
    "predictor_decisionTree = decisionTree.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MB8M0wNKQjn"
   },
   "outputs": [],
   "source": [
    "test_results_decisionTree = predictor_decisionTree.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mzix9dLdKQjo",
    "outputId": "0c661343-ccb1-4e89-b1dd-6a9ab0d31452"
   },
   "outputs": [],
   "source": [
    "test_results_decisionTree.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_decisionTree_rdd=test_results_decisionTree.select(\"label\",\"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictionAndLabels = test_results_NaiveBayes.select(\"label\",\"prediction\")\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "#predictionAndLabels = test_results_lg.select(\"label\",\"prediction\").rdd\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics_decisionTree = MulticlassMetrics(test_results_decisionTree_rdd)\n",
    "\n",
    "# Statistics by class\n",
    "labels = test_results_decisionTree_rdd.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics_decisionTree.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics_decisionTree.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics_decisionTree.fMeasure(label, beta=1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpdHmP2uKQjo",
    "outputId": "7af23189-9c0a-45c0-d6c4-dc34209e9c52"
   },
   "outputs": [],
   "source": [
    "acc_eval_decisionTree = MulticlassClassificationEvaluator()\n",
    "acc_decisionTree = acc_eval_decisionTree.evaluate(test_results_decisionTree)\n",
    "print(\"Accuracy of Model at  presicting like - dislike - neutral is: {}\".format(acc_decisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_decisionTree.save(\"Project_1_DecisionTree_pyspark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BP_qeSfTKQjo"
   },
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ro65C2HVKQjp"
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtvfygT9KQjp"
   },
   "outputs": [],
   "source": [
    "predictor_NaiveBayes = nb.fit(final_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQ1MZXZOKQjp"
   },
   "outputs": [],
   "source": [
    "test_results_NaiveBayes = predictor_NaiveBayes.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mER7TIfiKQjp",
    "outputId": "f761f23a-eb61-4629-a39a-90205d2ea153"
   },
   "outputs": [],
   "source": [
    "test_results_NaiveBayes.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4DUlyoYKQjp",
    "outputId": "9293088e-678e-46a9-9008-f25988e9a55f"
   },
   "outputs": [],
   "source": [
    "acc_eval_NaiveBayes = MulticlassClassificationEvaluator()\n",
    "acc_NaiveBayes = acc_eval_NaiveBayes.evaluate(test_results_NaiveBayes)\n",
    "print(\"Accuracy of Model at presicting  like - dislike - neutral is: {}\".format(acc_NaiveBayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_NaiveBayes_rdd=test_results_NaiveBayes.select(\"label\",\"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictionAndLabels = test_results_NaiveBayes.select(\"label\",\"prediction\")\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "#predictionAndLabels = test_results_lg.select(\"label\",\"prediction\").rdd\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(test_results_NaiveBayes_rdd)\n",
    "\n",
    "# Statistics by class\n",
    "labels = test_results_NaiveBayes_rdd.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_NaiveBayes.save(\"Project_1_NaiveBayes_pyspark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9fT2nHRKQjp"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KY4-kmWrKQjp"
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "M-WfVZPcKQjq"
   },
   "outputs": [],
   "source": [
    "predictor_lg = data_prep_pipe.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "cgz4usxNKQjq"
   },
   "outputs": [],
   "source": [
    "test_results_lg = predictor_lg.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "zEO6SB7dKQjq",
    "outputId": "5970afdb-516d-4c7a-9b28-6e448a0b3288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n",
      "|label|prediction| count|\n",
      "+-----+----------+------+\n",
      "|  1.0|       1.0| 12000|\n",
      "|  0.0|       1.0|   288|\n",
      "|  2.0|       2.0|  9791|\n",
      "|  1.0|       0.0|     9|\n",
      "|  2.0|       1.0|    89|\n",
      "|  1.0|       2.0|   734|\n",
      "|  0.0|       0.0|129733|\n",
      "|  0.0|       2.0|   172|\n",
      "+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results_lg.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(class='Not_Like', pre_comment='ổn tệ giặt', token_text=['ổn', 'tệ', 'giặt'], c_vec=SparseVector(41725, {5: 1.0, 38: 1.0, 74: 1.0}), tf_idf=SparseVector(41725, {5: 2.1615, 38: 4.4976, 74: 5.3195}), label=1.0, features=SparseVector(41726, {5: 2.1615, 38: 4.4976, 74: 5.3195, 41725: 1.0}), rawPrediction=DenseVector([-12.1404, 11.1856, 0.9548]), probability=DenseVector([0.0, 1.0, 0.0]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ổn tội_shop không_vưa cắt xấu hơi chán', token_text=['ổn', 'tội_shop', 'không_vưa', 'cắt', 'xấu', 'hơi', 'chán'], c_vec=SparseVector(41725, {5: 1.0, 18: 1.0, 41: 1.0, 77: 1.0, 121: 1.0, 4362: 1.0}), tf_idf=SparseVector(41725, {5: 2.1615, 18: 3.7702, 41: 4.5604, 77: 5.259, 121: 5.9048, 4362: 10.8392}), label=1.0, features=SparseVector(41726, {5: 2.1615, 18: 3.7702, 41: 4.5604, 77: 5.259, 121: 5.9048, 4362: 10.8392, 41725: 1.0}), rawPrediction=DenseVector([-8.8534, 10.9733, -2.1199]), probability=DenseVector([0.0, 1.0, 0.0]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ổn đẹp đen hỏng móc đỏ chú_ý', token_text=['ổn', 'đẹp', 'đen', 'hỏng', 'móc', 'đỏ', 'chú_ý'], c_vec=SparseVector(41725, {0: 1.0, 5: 1.0, 30: 1.0, 162: 1.0, 202: 1.0, 223: 1.0, 266: 1.0}), tf_idf=SparseVector(41725, {0: 0.9316, 5: 2.1615, 30: 4.265, 162: 6.3284, 202: 6.4973, 223: 6.6583, 266: 6.8689}), label=1.0, features=SparseVector(41726, {0: 0.9316, 5: 2.1615, 30: 4.265, 162: 6.3284, 202: 6.4973, 223: 6.6583, 266: 6.8689, 41725: 1.0}), rawPrediction=DenseVector([-9.9459, 10.4067, -0.4608]), probability=DenseVector([0.0, 1.0, 0.0]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ổn đẹp đeo cực cực tặng kèm', token_text=['ổn', 'đẹp', 'đeo', 'cực', 'cực', 'tặng', 'kèm'], c_vec=SparseVector(41725, {0: 1.0, 5: 1.0, 22: 1.0, 46: 2.0, 87: 1.0, 198: 1.0}), tf_idf=SparseVector(41725, {0: 0.9316, 5: 2.1615, 22: 3.9696, 46: 9.4765, 87: 5.4269, 198: 6.5527}), label=1.0, features=SparseVector(41726, {0: 0.9316, 5: 2.1615, 22: 3.9696, 46: 9.4765, 87: 5.4269, 198: 6.5527, 41725: 1.0}), rawPrediction=DenseVector([-12.9804, 10.2847, 2.6957]), probability=DenseVector([0.0, 0.9995, 0.0005]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ổn đọc', token_text=['ổn', 'đọc'], c_vec=SparseVector(41725, {5: 1.0, 228: 1.0}), tf_idf=SparseVector(41725, {5: 2.1615, 228: 6.7098}), label=1.0, features=SparseVector(41726, {5: 2.1615, 228: 6.7098, 41725: 1.0}), rawPrediction=DenseVector([-13.0351, 11.519, 1.5161]), probability=DenseVector([0.0, 1.0, 0.0]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ổn đồng_tiền nhiệt_tình mất_dạy đứng không không nhấn ném thẳng vô không từ_giã chạy không_chuyên_nghiệp', token_text=['ổn', 'đồng_tiền', 'nhiệt_tình', 'mất_dạy', 'đứng', 'không', 'không', 'nhấn', 'ném', 'thẳng', 'vô', 'không', 'từ_giã', 'chạy', 'không_chuyên_nghiệp'], c_vec=SparseVector(41725, {1: 3.0, 5: 1.0, 19: 1.0, 52: 1.0, 152: 1.0, 234: 1.0, 379: 1.0, 571: 1.0, 644: 1.0, 1517: 1.0, 3147: 1.0, 3716: 1.0}), tf_idf=SparseVector(41725, {1: 5.4759, 5: 2.1615, 19: 3.6921, 52: 4.7875, 152: 6.0844, 234: 6.726, 379: 7.3514, 571: 7.9649, 644: 8.2002, 1517: 9.4178, 3147: 10.3872, 3716: 10.5879}), label=1.0, features=SparseVector(41726, {1: 5.4759, 5: 2.1615, 19: 3.6921, 52: 4.7875, 152: 6.0844, 234: 6.726, 379: 7.3514, 571: 7.9649, 644: 8.2002, 1517: 9.4178, 3147: 10.3872, 3716: 10.5879, 41725: 1.0}), rawPrediction=DenseVector([-44.7802, 27.7653, 17.0149]), probability=DenseVector([0.0, 1.0, 0.0]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ổn đổi không phản_hồi tệ', token_text=['ổn', 'đổi', 'không', 'phản_hồi', 'tệ'], c_vec=SparseVector(41725, {1: 1.0, 5: 1.0, 26: 1.0, 74: 1.0, 217: 1.0}), tf_idf=SparseVector(41725, {1: 1.8253, 5: 2.1615, 26: 4.1645, 74: 5.3195, 217: 6.6176}), label=1.0, features=SparseVector(41726, {1: 1.8253, 5: 2.1615, 26: 4.1645, 74: 5.3195, 217: 6.6176, 41725: 1.0}), rawPrediction=DenseVector([-11.9944, 11.7611, 0.2333]), probability=DenseVector([0.0, 1.0, 0.0]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ổn ổn', token_text=['ổn', 'ổn'], c_vec=SparseVector(41725, {5: 2.0}), tf_idf=SparseVector(41725, {5: 4.323}), label=1.0, features=SparseVector(41726, {5: 4.323, 41725: 1.0}), rawPrediction=DenseVector([-12.3245, 10.2627, 2.0619]), probability=DenseVector([0.0, 0.9997, 0.0003]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ổn ổn ăâêôươqwertyuiopđlkjhgfdsazxcvbnmăâêôươqwsafhction', token_text=['ổn', 'ổn', 'ăâêôươqwertyuiopđlkjhgfdsazxcvbnmăâêôươqwsafhction'], c_vec=SparseVector(41725, {5: 2.0}), tf_idf=SparseVector(41725, {5: 4.323}), label=1.0, features=SparseVector(41726, {5: 4.323, 41725: 1.0}), rawPrediction=DenseVector([-12.3245, 10.2627, 2.0619]), probability=DenseVector([0.0, 0.9997, 0.0003]), prediction=1.0),\n",
       " Row(class='Not_Like', pre_comment='ủng_hộ sắm', token_text=['ủng_hộ', 'sắm'], c_vec=SparseVector(41725, {9: 1.0, 530: 1.0}), tf_idf=SparseVector(41725, {9: 2.8339, 530: 7.9649}), label=1.0, features=SparseVector(41726, {9: 2.8339, 530: 7.9649, 41725: 1.0}), rawPrediction=DenseVector([-14.5168, 10.5368, 3.9799]), probability=DenseVector([0.0, 0.9986, 0.0014]), prediction=1.0)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_lg.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_lg_rdd=test_results_lg.select(\"label\",\"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 precision = 0.9964667839284754\n",
      "Class 0.0 recall = 0.9999306315610982\n",
      "Class 0.0 F1 Measure = 0.9981957027718469\n",
      "Class 1.0 precision = 0.9416934787726595\n",
      "Class 1.0 recall = 0.9695402763189788\n",
      "Class 1.0 F1 Measure = 0.9554140127388535\n",
      "Class 2.0 precision = 0.9909919028340081\n",
      "Class 2.0 recall = 0.9153033560811442\n",
      "Class 2.0 F1 Measure = 0.9516450405792876\n"
     ]
    }
   ],
   "source": [
    "#predictionAndLabels = test_results_NaiveBayes.select(\"label\",\"prediction\")\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "\n",
    "#predictionAndLabels = test_results_lg.select(\"label\",\"prediction\").rdd\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(test_results_lg_rdd)\n",
    "\n",
    "# Statistics by class\n",
    "labels = test_results_lg_rdd.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "JtRAveVxKQjq",
    "outputId": "16165815-2ca1-4c35-bf13-b181e64168c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting  like - dislike - neutral is: 0.9916185929237098\n"
     ]
    }
   ],
   "source": [
    "acc_eval_lg = MulticlassClassificationEvaluator()\n",
    "acc_lg = acc_eval_lg.evaluate(test_results_lg)\n",
    "print(\"Accuracy of model at predicting  like - dislike - neutral is: {}\".format(acc_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lg.save('Project_1_LogisticRegression_pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOAD EMOJICON\n",
    "file = open('files/emojicon.txt', 'r', encoding=\"utf8\")\n",
    "emoji_lst = file.read().split('\\n')\n",
    "emoji_dict = {}\n",
    "for line in emoji_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    emoji_dict[key] = str(value)\n",
    "file.close()\n",
    "#################\n",
    "#LOAD TEENCODE\n",
    "file = open('files/teencode.txt', 'r', encoding=\"utf8\")\n",
    "teen_lst = file.read().split('\\n')\n",
    "teen_dict = {}\n",
    "for line in teen_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    teen_dict[key] = str(value)\n",
    "file.close()\n",
    "###############\n",
    "#LOAD TRANSLATE ENGLISH -> VNMESE\n",
    "file = open('files/english-vnmese.txt', 'r', encoding=\"utf8\")\n",
    "english_lst = file.read().split('\\n')\n",
    "english_dict = {}\n",
    "for line in english_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    english_dict[key] = str(value)\n",
    "file.close()\n",
    "################\n",
    "#LOAD wrong words\n",
    "file = open('files/wrong-word.txt', 'r', encoding=\"utf8\")\n",
    "wrong_lst = file.read().split('\\n')\n",
    "file.close()\n",
    "#################\n",
    "#LOAD STOPWORDS\n",
    "file = open('files/vietnamese-stopwords.txt', 'r', encoding=\"utf8\")\n",
    "stopwords_lst = file.read().split('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, emoji_dict, teen_dict, wrong_lst):\n",
    "    document = text.lower()\n",
    "    document = document.replace(\"’\",'')\n",
    "    document = regex.sub(r'\\.+', \".\", document)\n",
    "    new_sentence =''\n",
    "    for sentence in sent_tokenize(document):\n",
    "        # if not(sentence.isascii()):\n",
    "        ###### CONVERT EMOJICON\n",
    "        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))\n",
    "        ###### CONVERT TEENCODE\n",
    "        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())\n",
    "        ###### DEL Punctuation & Numbers\n",
    "        pattern = r'(?i)\\b[a-záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ]+\\b'\n",
    "        sentence = ' '.join(regex.findall(pattern,sentence))\n",
    "        ###### DEL wrong words   \n",
    "        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())\n",
    "        new_sentence = new_sentence+ sentence + '. '                    \n",
    "    document = new_sentence  \n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa unicode tiếng việt\n",
    "def loaddicchar():\n",
    "    uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "    unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    " \n",
    "# Đưa toàn bộ dữ liệu qua hàm này để chuẩn hóa lại\n",
    "def convert_unicode(txt):\n",
    "    dicchar = loaddicchar()\n",
    "    return regex.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# có thể bổ sung thêm các từ: chẳng, chả...\n",
    "def process_special_word(text):\n",
    "    new_text = ''\n",
    "    text_lst = text.split()\n",
    "    i= 0\n",
    "    if 'không' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "#             print(word)\n",
    "#             print(i)\n",
    "            if  word == 'không':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "#                     print(word)\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "    if 'tạm' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "#             print(word)\n",
    "#             print(i)\n",
    "            if  word == 'tạm':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "#                     print(word)\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "    if 'hơi' in text_lst:\n",
    "        while i <= len(text_lst) - 1:\n",
    "            word = text_lst[i]\n",
    "#             print(word)\n",
    "#             print(i)\n",
    "            if  word == 'hơi':\n",
    "                next_idx = i+1\n",
    "                if next_idx <= len(text_lst) -1:\n",
    "                    word = word +'_'+ text_lst[next_idx]\n",
    "#                     print(word)\n",
    "                i= next_idx + 1\n",
    "            else:\n",
    "                i = i+1\n",
    "            new_text = new_text + word + ' '\n",
    "            #print(new_text)\n",
    "    else:\n",
    "        new_text = text\n",
    "    return new_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_postag_thesea(text):\n",
    "    new_document = ''\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('.','')\n",
    "        ###### POS tag\n",
    "        lst_word_type = ['A','AB','V','VB','VY','R','M','N','NP']\n",
    "        #lst_word_type = ['A','AB','V','VB','VY','R']\n",
    "        sentence = ' '.join( word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format=\"text\"))))\n",
    "        new_document = new_document + sentence + ' '\n",
    "    ###### DEL excess blank space\n",
    "    new_document = regex.sub(r'\\s+', ' ', new_document).strip()\n",
    "    return new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text, stopwords):\n",
    "    ###### REMOVE stop words\n",
    "    document = ' '.join('' if word in stopwords else word for word in text.split())\n",
    "    #print(document)\n",
    "    ###### DEL excess blank space\n",
    "    document = regex.sub(r'\\s+', ' ', document).strip()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import LogisticRegressionModel\n",
    "# model_1 = LogisticRegressionModel.load('Project_1_LogisticRegression_pyspark_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_1=\"Hàng Shopee Mall chuẩn code. Chất lỏng, lớp finish ẩm mượt, nâng tông tuy nhiên thì với bạn nào có oily-skin như mình sản phẩm có vẻ phù hợp 80% (thêm 1 lớp phấn phủ sẽ Okiela hơn nha)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xu_li_text(text):\n",
    "    document=  process_text(text,emoji_dict,teen_dict,wrong_lst)\n",
    "    document = convert_unicode(document)\n",
    "    document = process_postag_thesea(document)\n",
    "    document = remove_stopword(document, stopwords_lst)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------+-----+\n",
      "|pre_comment                                                                                 |label|\n",
      "+--------------------------------------------------------------------------------------------+-----+\n",
      "|hàng shopee chuẩn chất_lỏng lớp finish ẩm mượt nâng tông nhiên oily skin lớp phấn phủ okiela|5    |\n",
      "+--------------------------------------------------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StringType\n",
    "sentences = spark.createDataFrame([\n",
    "    Row(pre_comment=xu_li_text(str_1),label=5)])\n",
    "sentences.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = cleaner.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_1=predictor_lg.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_1.select(\"pre_comment\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prec_1.select(\"prediction\").collect()[0][0]==1.0:\n",
    "    print(\"Like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0:like\n",
    "2: dislike\n",
    "1: neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "pipeline_test=PipelineModel.load('Project_1_Pipeline_pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pipeline_test.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_sentence = \"Thật sự không thích sản phẩm này\"\n",
    "# new_df = spark.createDataFrame([(new_sentence,)], [\"pre_comment\"])\n",
    "prediction = predictor_lg.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|         pre_comment|label|          token_text|               c_vec|              tf_idf|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|hàng shopee chuẩn...|    5|[hàng, shopee, ch...|(41725,[35,49,149...|(41725,[35,49,149...|(41726,[35,49,149...|[-198.19884419223...|[2.92609995502389...|       2.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JDd8n73KQjq"
   },
   "source": [
    "### Nhận xét:\n",
    "- Các model chạy bằng thư viện pyspark đều cho ra kết quả khá tốt (83 - 99%).\n",
    "- Xem xét recall, f1 Measure, precision ta thấy model NaiveBayes chưa thực sự tốt. Ngược lại model LogisticRegression cho ra accuracy lẫn recall, f1 Measure, precision đều khá cao.\n",
    "\n",
    "=> Model LogisticRegression cho ra kết quả tốt nhất và có thể áp dụng model này.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Do cấu hình máy yếu nên em không thể chạy model RandomForestClassifier và một số model còn lại.\n",
    "- Các model GBT, SVC chỉ hỗ trợ chạy được 2 classes không thể chạy 3 classes trở lên"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JXCJ4axKQjq"
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lwtq1U1qKQjr"
   },
   "outputs": [],
   "source": [
    "# rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4EWX9TAKQjr"
   },
   "outputs": [],
   "source": [
    "# predictor_rfc = rfc.fit(final_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GB6lmzJrKQjr"
   },
   "outputs": [],
   "source": [
    "# test_results_rfc = predictor_rfc.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qxneC-4KQjr"
   },
   "outputs": [],
   "source": [
    "# test_results_rfc.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-zyyeRAKQjr"
   },
   "outputs": [],
   "source": [
    "# acc_eval_rfc = MulticlassClassificationEvaluator()\n",
    "# acc_rfc = acc_eval_rfc.evaluate(test_results_rfc)\n",
    "# print(\"Accuracy of Model at  presicting like - dislike - neutral is: {}\".format(acc_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqr5bD9XKQjr"
   },
   "source": [
    "### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAu3k2BSKQjr"
   },
   "outputs": [],
   "source": [
    "# gbt= GBTClassifier(maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNNctUNgKQjs"
   },
   "outputs": [],
   "source": [
    "# predictor_gbt = gbt.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKE150TZKQjs"
   },
   "outputs": [],
   "source": [
    "# test_results_gbt = predictor_gbt.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuFfcSPEKQjs"
   },
   "outputs": [],
   "source": [
    "# test_results_gbt.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFoPbZbsKQjs"
   },
   "outputs": [],
   "source": [
    "# acc_eval_gbt = MulticlassClassificationEvaluator()\n",
    "# acc_gbt = acc_eval_gbt.evaluate(test_results_gbt)\n",
    "# print(\"Accuracy of Model at  presicting spam ham is: {}\".format(acc_gbt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOCaBI9WKQjs"
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KnXOha-1KQjs"
   },
   "outputs": [],
   "source": [
    "# lsvc = LinearSVC(maxIter=10, regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4R2iJHptKQjs"
   },
   "outputs": [],
   "source": [
    "# predictor_lsvc = lsvc.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABgizR92KQjs"
   },
   "outputs": [],
   "source": [
    "# test_results_lsvc = predictor_lsvc.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD7P2XKcKQjt"
   },
   "outputs": [],
   "source": [
    "# test_results_lsvc.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsvrFHNrKQjt"
   },
   "outputs": [],
   "source": [
    "# acc_eval_lsvc = MulticlassClassificationEvaluator()\n",
    "# acc_lsvc = acc_eval_lsvc.evaluate(test_results_lg)\n",
    "# print(\"Accuracy of model at predicting  like - dislike - neutral is: {}\".format(acc_lsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnIpFa4eKQjt"
   },
   "source": [
    "### One and Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzEBc6nlKQjt"
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import OneVsRest\n",
    "# ovr = OneVsRest(classifier=GBTClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FG1yDNfeKQjt"
   },
   "outputs": [],
   "source": [
    "# predictor_ovr = ovr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtnvPq8uKQjt"
   },
   "outputs": [],
   "source": [
    "# test_results_ovr = predictor_ovr.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOdsMQ6BKQju"
   },
   "outputs": [],
   "source": [
    "# test_results_ovr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCh3AUK8KQju"
   },
   "outputs": [],
   "source": [
    "# test_results_ovr.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNL4nEu0KQju"
   },
   "outputs": [],
   "source": [
    "# acc_eval = MulticlassClassificationEvaluator()\n",
    "# acc_1 = acc_eval.evaluate(test_results_ovr)\n",
    "# print(\"Accuracy of model at predicting: {}\".format(acc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3MfYahWKQju"
   },
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
