{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Zr4aoEgQMB2m",
    "outputId": "f57c6f76-5cd4-4540-871b-610dda69ebbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khaih\\Downloads\\LDS0\\Data\n"
     ]
    }
   ],
   "source": [
    "%cd \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tlwqMKULMB2o",
    "outputId": "0c3201f9-6d4e-4c5f-d1af-3f2b1afe8313"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\khaih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YpbfKcxOMB2p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "import regex\n",
    "import demoji\n",
    "from pyvi import ViPosTagger, ViTokenizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3tMcWrytMB2p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I7usSZy8MB2p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"pre_data_8.csv\", delimiter=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "T72RfGcSMB2q",
    "outputId": "3c8c366d-9088-45d2-be31-db8ec0aa7c86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>pre_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259179</th>\n",
       "      <td>Like</td>\n",
       "      <td>kiểm đồ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259180</th>\n",
       "      <td>Like</td>\n",
       "      <td>cho_phép sơ_suất troâm nhạc hát hoạt_động nhậv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259181</th>\n",
       "      <td>Like</td>\n",
       "      <td>vừa_vặn nâu trăng dày hơn đỏ trắng đỏ cổ hơn n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259182</th>\n",
       "      <td>Like</td>\n",
       "      <td>đầu_shop hợp mùa hè</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259183</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp đẹp nhanh thích</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259184</th>\n",
       "      <td>Like</td>\n",
       "      <td>đẹp dày_dặn nhanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259185</th>\n",
       "      <td>Like</td>\n",
       "      <td>mét sáu_mươi_lăm lô gờ fit luônn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259186</th>\n",
       "      <td>Like</td>\n",
       "      <td>không_không không_nhỉ quên học</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259187</th>\n",
       "      <td>Like</td>\n",
       "      <td>chê tốt_đẹp hợp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259188</th>\n",
       "      <td>Like</td>\n",
       "      <td>gọn_gàng đẹp ôm tôn dáng hình_ảnh kâng họa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                        pre_comment\n",
       "259179  Like                                            kiểm đồ\n",
       "259180  Like  cho_phép sơ_suất troâm nhạc hát hoạt_động nhậv...\n",
       "259181  Like  vừa_vặn nâu trăng dày hơn đỏ trắng đỏ cổ hơn n...\n",
       "259182  Like                                đầu_shop hợp mùa hè\n",
       "259183  Like                                đẹp đẹp nhanh thích\n",
       "259184  Like                                  đẹp dày_dặn nhanh\n",
       "259185  Like                   mét sáu_mươi_lăm lô gờ fit luônn\n",
       "259186  Like                     không_không không_nhỉ quên học\n",
       "259187  Like                                    chê tốt_đẹp hợp\n",
       "259188  Like         gọn_gàng đẹp ôm tôn dáng hình_ảnh kâng họa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MKhlw3mQMB2q",
    "outputId": "60c5d14a-ae42-4add-98c9-c96cc11aa93f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class          0\n",
       "pre_comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "n2PPj7rGMB2q",
    "outputId": "067da707-daf2-48da-fae7-079f4b7175fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class          526579\n",
       "pre_comment    526579\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_YZ6GGSDMB2q"
   },
   "outputs": [],
   "source": [
    "X=data[\"pre_comment\"]\n",
    "y=data[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R4NvCa-mMB2q"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yGCVqeI3MB2r"
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(np.array(X_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1));\n",
    "train_df_reampled = pd.DataFrame(list(zip([x[0] for x in X_train_resampled], y_train_resampled)), columns = ['pre_comment', 'class']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cIuLAhxYMB2r",
    "outputId": "fe36ca79-4398-4720-ef6e-bfe282d4ecb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Like        359326\n",
       "Neutral     359326\n",
       "Not_Like    359326\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_reampled[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_reampled.to_csv(\"data_resample_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OXZN3sssMB2r"
   },
   "outputs": [],
   "source": [
    "X_train_resampled, X_test, y_train_resampled, y_test = train_test_split(train_df_reampled[\"pre_comment\"],train_df_reampled[\"class\"], test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_reampled.loc[train_df_reampled[\"pre_comment\"]==\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqhNNDDDMB2r"
   },
   "outputs": [],
   "source": [
    "X_train_resampled=train_df_reampled[\"pre_comment\"]\n",
    "y_train_resampled=train_df_reampled[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6Loz_xIMB2s"
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# vectorizer.fit(X_train.values)\n",
    "# X_train=vectorizer.transform(X_train.values)\n",
    "# X_test=vectorizer.transform(X_test.values)\n",
    "# X_train=X_train.toarray()\n",
    "# X_test=X_test.toarray()\n",
    "\n",
    "# x_train = pd.DataFrame(X_train)\n",
    "# X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3K1leY7TMB2s"
   },
   "outputs": [],
   "source": [
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vTm5gwXlMB2s"
   },
   "outputs": [],
   "source": [
    "def my_tokenizer(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByBEmrxyMB2s"
   },
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XMtTrco0MB2u",
    "outputId": "714ca70c-9121-4c55-9036-0b57015ecc3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7905898068609807\n",
      "------------------------------------------------------------\n",
      "[[59496 10267  2446]\n",
      " [ 4989 55817 10859]\n",
      " [ 1876 14711 55135]]\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Like       0.90      0.82      0.86     72209\n",
      "     Neutral       0.69      0.78      0.73     71665\n",
      "    Not_Like       0.81      0.77      0.79     71722\n",
      "\n",
      "    accuracy                           0.79    215596\n",
      "   macro avg       0.80      0.79      0.79    215596\n",
      "weighted avg       0.80      0.79      0.79    215596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_bnl = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', BernoulliNB())\n",
    "])\n",
    "\n",
    "pipeline_bnl.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_bnl = pipeline_bnl.predict(X_test)\n",
    "\n",
    "accuracy_bnl = accuracy_score(y_test, y_pred_bnl)\n",
    "print(\"Accuracy: \", accuracy_bnl)\n",
    "print(\"-\"*60)\n",
    "print(confusion_matrix(y_test, y_pred_bnl))\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred_bnl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePmBQsIgMB2u"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "t9Bd_2BEMB2v",
    "outputId": "70a9af93-c5fa-46d8-8968-f526d18bfde9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khaih\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8113972429915212\n",
      "------------------------------------------------------------\n",
      "[[62498  7269  2442]\n",
      " [ 5238 54457 11970]\n",
      " [ 2259 11484 57979]]\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Like       0.89      0.87      0.88     72209\n",
      "     Neutral       0.74      0.76      0.75     71665\n",
      "    Not_Like       0.80      0.81      0.80     71722\n",
      "\n",
      "    accuracy                           0.81    215596\n",
      "   macro avg       0.81      0.81      0.81    215596\n",
      "weighted avg       0.81      0.81      0.81    215596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline_lr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_lr = pipeline_lr.predict(X_test)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"-\"*60)\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(pipeline_lr, 'Project_1_LogisticRegression_sklearn_3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxQEdHTgMB2v"
   },
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6PWIeIJ9MB2v",
    "outputId": "a8be7bbb-063a-424e-b3ab-be3cd92465f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9260700569583852\n",
      "------------------------------------------------------------\n",
      "[[63947  4440  3822]\n",
      " [ 1227 67362  3076]\n",
      " [  523  2851 68348]]\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Like       0.97      0.89      0.93     72209\n",
      "     Neutral       0.90      0.94      0.92     71665\n",
      "    Not_Like       0.91      0.95      0.93     71722\n",
      "\n",
      "    accuracy                           0.93    215596\n",
      "   macro avg       0.93      0.93      0.93    215596\n",
      "weighted avg       0.93      0.93      0.93    215596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_dct = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_dct.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_dct = pipeline_dct.predict(X_test)\n",
    "\n",
    "accuracy_dct = accuracy_score(y_test, y_pred_dct)\n",
    "print(\"Accuracy:\", accuracy_dct)\n",
    "print(\"-\"*60)\n",
    "print(confusion_matrix(y_test, y_pred_dct))\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred_dct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project_1_DecisionTree_sklearn_4.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(pipeline_dct, 'Project_1_DecisionTree_sklearn_4.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9313298948032431\n",
      "------------------------------------------------------------\n",
      "[[65081  3387  3741]\n",
      " [ 1227 67362  3076]\n",
      " [  525  2849 68348]]\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Like       0.97      0.90      0.94     72209\n",
      "     Neutral       0.92      0.94      0.93     71665\n",
      "    Not_Like       0.91      0.95      0.93     71722\n",
      "\n",
      "    accuracy                           0.93    215596\n",
      "   macro avg       0.93      0.93      0.93    215596\n",
      "weighted avg       0.93      0.93      0.93    215596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_etc = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', ExtraTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline_etc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_etc = pipeline_etc.predict(X_test)\n",
    "\n",
    "accuracy_etc = accuracy_score(y_test, y_pred_etc)\n",
    "print(\"Accuracy: \", accuracy_etc)\n",
    "print(\"-\"*60)\n",
    "print(confusion_matrix(y_test, y_pred_etc))\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_test, y_pred_etc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project_1_Extra_sklearn_4.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(pipeline_dct, 'Project_1_Extra_sklearn_4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[\"dở_tệ không tiền\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[\"dở_tệ không tiền\"]\n",
    "text=pd.DataFrame({'pre_comment':text})\n",
    "import joblib\n",
    "loaded_model = joblib.load(\"Project_1_sklearn.joblib\")\n",
    "result = loaded_model.predict(text[\"pre_comment\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4zyH4X4MB2x"
   },
   "source": [
    "### Nhận xét:\n",
    "- Sau khi resample data nhận thấy rằng accuracy giảm đi, nhưng recall và f1-score tăng đáng kể, cho thấy tính hiệu quả được cải thiện.\n",
    "\n",
    "=> Có thể chấp nhận các model đã chạy qua cách cải thiện resample data. \n",
    "\n",
    "=> Model DecisionTree và ExtraTreeClassifier cho ra kết quả tốt nhất và có thể áp dụng nó để predict (Accuracy lần lượt là: 89,6% và 90%), đồng thời các điểm recall, f1-score đều khá cao dao động từ (88%-93%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYX84VKcMB2x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
